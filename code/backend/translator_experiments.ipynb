{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f98cf714-0149-4f69-aae4-d779ad01bb8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import speech\n",
    "from google.cloud import texttospeech\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b86cb91-816d-4f89-bc78-1ac3c8ff5ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"jai-dev-mlconsole-poc.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "267364e4-c9bf-47c6-95fb-b27642b59ed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speech_client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59d91c0b-db35-4ae9-b4a3-c2698610d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"../mono.wav\"\n",
    "file_path = \"../audio.wav\"\n",
    "with open(file_path, 'rb') as audio:\n",
    "    data=audio.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bdef81d-f6b6-4a6c-a1c6-d93a64afcd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = speech.RecognitionAudio(content=data)\n",
    "config = speech.RecognitionConfig(\n",
    "    # encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=44100,\n",
    "    language_code=\"en-US\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6cc6425c-58b1-467c-be44-a9ab57158195",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = speech_client.recognize(config=config, audio=audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbecae35-049e-4453-8c5a-abdfb2d2ced3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcription_list = []\n",
    "for result in response.results:\n",
    "    transcription_list.append(result.alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8435c2e-283a-4997-810e-8fbe6926203d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transcription = \" \".join(transcription_list)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75d5c25a-e675-4882-9640-baf0efce3091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d129f079-f945-4c6d-956e-0e61313d6c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio content written to file \"output.mp3\"\n"
     ]
    }
   ],
   "source": [
    "# Instantiates a client\n",
    "text_client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Set the text input to be synthesized\n",
    "# synthesis_input = texttospeech.SynthesisInput(text=\"Hello, World!\")\n",
    "synthesis_input = texttospeech.SynthesisInput(text=\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\")\n",
    "\n",
    "# Build the voice request, select the language code (\"en-US\") and the ssml\n",
    "voice gender (\"neutral\")\n",
    "voice = texttospeech.VoiceSelectionParams(\n",
    "    language_code=\"fr-FR\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    ")\n",
    "\n",
    "# Select the type of audio file you want returned\n",
    "audio_config = texttospeech.AudioConfig(\n",
    "    audio_encoding=texttospeech.AudioEncoding.MP3\n",
    ")\n",
    "\n",
    "# Perform the text-to-speech request on the text input with the selected\n",
    "# voice parameters and audio file type\n",
    "response = text_client.synthesize_speech(\n",
    "    input=synthesis_input, voice=voice, audio_config=audio_config\n",
    ")\n",
    "\n",
    "# The response's audio_content is binary.\n",
    "with open(\"output.mp3\", \"wb\") as out:\n",
    "    # Write the response to the output file.\n",
    "    out.write(response.audio_content)\n",
    "    print('Audio content written to file \"output.mp3\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf74ce-8d55-445c-8be5-2e93db80fddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d92f21-04e0-4d5a-8e46-0373aad4e221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de94774-1485-4ca2-a6bd-e71af61be41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00581829-8448-424b-8eb9-a55e4f1ec79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_english_sentences = np.load('preproc_english_sentences.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e03c6805-5078-486e-8bd2-ea70618845ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_english_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "802d936f-36df-40cb-8cc0-f2e51c230b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_eng = preproc_english_sentences.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dbe2856-f200-4bd4-a9d7-c4ad63fddef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(max_len_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0f6e6c2-2fea-4b68-9986-f7c4cf0e3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [max_len_eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53a1c2e0-9425-495e-b96e-9af131ff2d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8b1c71-28bb-45c1-8589-24943f543ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"max_len_arr.npy\", lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b1f5f56-7237-4537-b129-ee6191f0dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nparr = np.load(\"max_len_arr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8470a009-d8b5-481e-aae1-9c2af2e4f2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d619939-fc13-4d6c-b403-33282c8ee139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nparr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16c80673-267c-4092-ab98-190118c7af01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nparr.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c07f195-af54-4995-83cd-547d41d58c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preproc_english_sentences.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c05a9b7b-6e19-4b43-b5db-0ea9b7c475f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ebebf39a-74fb-421a-9a34-c596e6debd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='he watch a old yellow car'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "576fc113-a5dc-4b41-8d6f-bcad35a044d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english_tokenizer.pickle', 'rb') as handle:\n",
    "     english_tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b6561977-fb27-4152-b0e6-0a32c43ee967",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1c2bd504-ab61-4f0f-8c13-5ee333da2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sentence.split(\" \"):\n",
    "    if english_tokenizer.word_index.get(word):\n",
    "        lst.append(english_tokenizer.word_index.get(word))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4d3bb68c-7d6f-4469-ac13-ff6e6653bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c82014ad-98a2-4748-a2b6-332a5b655056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_predictions(self, model, sentence, french_tokenizer, english_tokenizer, max_len):\n",
    "        \"\"\"\n",
    "           Turn logits from a neural network into text using the tokenizer\n",
    "           :param sentence: sequence of string or single sentence\n",
    "           :param french_tokenizer: tokenize form of french dataa set\n",
    "           :param english_tokenizer:tokenize form of english data set\n",
    "           :param preproc_english_sentences\n",
    "           :return: predicted english sentece\n",
    "        \"\"\"\n",
    "\n",
    "        # sentence = [english_tokenizer.word_index[word] for word in sentence.split()]\n",
    "\n",
    "        lst=[]\n",
    "        for word in sentence.split(\" \"):\n",
    "            if english_tokenizer.word_index.get(word):\n",
    "                lst.append(english_tokenizer.word_index.get(word))\n",
    "        print(lst)        \n",
    "        lst=pad_sequences([lst],maxlen=max_len,padding='post')        \n",
    "        \n",
    "        # sentence = pad_sequences([sentence],maxlen=max_len,padding='post')\n",
    "        lst = model.predict(lst, len(lst))\n",
    "        # reshaping because after prediction size is (1,21,345)\n",
    "        lst = lst.reshape(21, 345)\n",
    "\n",
    "        #object of preprocessing class\n",
    "        prep=preprocessing()\n",
    "\n",
    "        res = prep.logits_to_text(lst, french_tokenizer)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821795f-45ef-4405-a219-1cb582fbd536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
