{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a9df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9897803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 18:47:33.367790: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-01-26 18:47:33.602739: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2594120000 Hz\n",
      "2022-01-26 18:47:33.612255: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe404000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-26 18:47:33.612309: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-26 18:47:33.697039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-26 18:47:34.006028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 18:47:34.006818: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dea92d08f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-26 18:47:34.006849: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce 840M, Compute Capability 5.0\n",
      "2022-01-26 18:47:34.035498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 18:47:34.035939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: GeForce 840M computeCapability: 5.0\n",
      "coreClock: 1.124GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 13.41GiB/s\n",
      "2022-01-26 18:47:34.058650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-26 18:47:34.351068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-26 18:47:34.607874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-26 18:47:34.673350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-26 18:47:34.939911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-26 18:47:34.996730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-26 18:47:35.553980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-26 18:47:35.554291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 18:47:35.554873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 18:47:35.555296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-26 18:47:35.576127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-26 18:47:35.613556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-26 18:47:35.613595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-01-26 18:47:35.613608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-01-26 18:47:35.633075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 18:47:35.633673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 18:47:35.740508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1561 MB memory) -> physical GPU (device: 0, name: GeForce 840M, pci bus id: 0000:0a:00.0, compute capability: 5.0)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0159853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9f9fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English data\n",
    "english_sentences ='data/small_vocab_en'\n",
    "# Load French data\n",
    "french_sentences ='data/small_vocab_fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488b950",
   "metadata": {},
   "source": [
    "load_data(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "582892b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences=load_data(english_sentences);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54f0f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_sentences=load_data(french_sentences);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "957f64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences, X_test, french_sentences, y_test = train_test_split(english_sentences, french_sentences, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70cff3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sample 1:  the united states is never beautiful during november , and it is never quiet in july .\n",
      "French sample 1:  les états-unis est jamais belle au mois de novembre , et il est jamais tranquille en juillet .\n",
      "\n",
      "English sample 2:  the monkey is your least favorite animal .\n",
      "French sample 2:  le singe est votre animal préféré moins .\n",
      "\n",
      "English sample 3:  california is never cold during winter , but it is never quiet in fall .\n",
      "French sample 3:  californie ne fait jamais froid pendant l' hiver , mais il est jamais tranquille à l' automne .\n",
      "\n",
      "English sample 4:  the peach is their most loved fruit , but the lemon is his most loved .\n",
      "French sample 4:  la pêche est leur fruit le plus cher , mais le citron est le plus aimé .\n",
      "\n",
      "English sample 5:  your most loved animals were horses .\n",
      "French sample 5:  vos animaux les plus aimés étaient des chevaux .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(5):\n",
    "    print('English sample {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('French sample {}:  {}\\n'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c347643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221686 English words.\n",
      "227 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"usually\"\n",
      "\n",
      "1314022 French words.\n",
      "353 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f240a979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    # TODO: Implement\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    return tokenizer.texts_to_sequences(x), tokenizer\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c1b12ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    return pad_sequences(x, maxlen=length, padding='post')\n",
    "\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4573269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of preproc_english_sentences 92366\n",
      "length of preproc_french_sentences 92366\n",
      "length of english_tokenizer <keras_preprocessing.text.Tokenizer object at 0x7f71c0f70b50>\n",
      "length of french_tokenizer <keras_preprocessing.text.Tokenizer object at 0x7f71c17aadd0>\n",
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 343\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "preprocess(english_sentences, french_sentences)\n",
    "\n",
    "print('length of preproc_english_sentences',len(preproc_english_sentences)) \n",
    "print('length of preproc_french_sentences',len(preproc_english_sentences))  \n",
    "print('length of english_tokenizer',english_tokenizer)\n",
    "print('length of french_tokenizer',french_tokenizer)\n",
    "    \n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)+1\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21ed149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preproc_english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2c7f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4eae8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.003\n",
    "    \n",
    "    # Build the layers    \n",
    "    model = Sequential()\n",
    "    # Embedding\n",
    "    model.add(Embedding(english_vocab_size, 128, input_length=input_shape[1],\n",
    "                         input_shape=input_shape[1:]))\n",
    "    # Encoder\n",
    "    model.add(Bidirectional(GRU(128)))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    # Decoder\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(512, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# tests.test_model_final(model_final)\n",
    "\n",
    "# print('Final Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76db422d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 20:15:10.768564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 20:15:10.769220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: GeForce 840M computeCapability: 5.0\n",
      "coreClock: 1.124GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 13.41GiB/s\n",
      "2022-01-25 20:15:10.769291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-25 20:15:10.769321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-25 20:15:10.769348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-25 20:15:10.769373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-25 20:15:10.769399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-25 20:15:10.769424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-25 20:15:10.769449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-25 20:15:10.769540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 20:15:10.770530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 20:15:10.771159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-25 20:15:10.772075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 20:15:10.772576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: GeForce 840M computeCapability: 5.0\n",
      "coreClock: 1.124GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 13.41GiB/s\n",
      "2022-01-25 20:15:10.772641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-25 20:15:10.772669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-25 20:15:10.772693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-25 20:15:10.772716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-25 20:15:10.772739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-25 20:15:10.772802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-25 20:15:10.772829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-25 20:15:10.772940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 20:15:10.774022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 20:15:10.774420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-25 20:15:10.774465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-25 20:15:10.774479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-01-25 20:15:10.774493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-01-25 20:15:10.774650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 20:15:10.775132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 20:15:10.775556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1579 MB memory) -> physical GPU (device: 0, name: GeForce 840M, pci bus id: 0000:0a:00.0, compute capability: 5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 15, 128)           25600     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 21, 256)           296448    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 21, 512)           131584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 21, 343)           175959    \n",
      "=================================================================\n",
      "Total params: 827,735\n",
      "Trainable params: 827,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 20:18:23.718429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-25 20:18:23.921199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 52s 711ms/step - loss: 2.7767 - accuracy: 0.4484 - val_loss: 1.8898 - val_accuracy: 0.5160\n",
      "Epoch 2/25\n",
      "73/73 [==============================] - 50s 687ms/step - loss: 1.6860 - accuracy: 0.5684 - val_loss: 1.3871 - val_accuracy: 0.6389\n",
      "Epoch 3/25\n",
      "73/73 [==============================] - 51s 697ms/step - loss: 1.3423 - accuracy: 0.6396 - val_loss: 1.1549 - val_accuracy: 0.6745\n",
      "Epoch 4/25\n",
      "73/73 [==============================] - 51s 700ms/step - loss: 1.1493 - accuracy: 0.6763 - val_loss: 0.9882 - val_accuracy: 0.7167\n",
      "Epoch 5/25\n",
      "73/73 [==============================] - 51s 697ms/step - loss: 1.0139 - accuracy: 0.7050 - val_loss: 0.9860 - val_accuracy: 0.7093\n",
      "Epoch 6/25\n",
      "73/73 [==============================] - 50s 687ms/step - loss: 0.9231 - accuracy: 0.7238 - val_loss: 0.8079 - val_accuracy: 0.7539\n",
      "Epoch 7/25\n",
      "73/73 [==============================] - 51s 695ms/step - loss: 0.8266 - accuracy: 0.7470 - val_loss: 0.6869 - val_accuracy: 0.7867\n",
      "Epoch 8/25\n",
      "73/73 [==============================] - 50s 683ms/step - loss: 0.7139 - accuracy: 0.7776 - val_loss: 0.5895 - val_accuracy: 0.8162\n",
      "Epoch 9/25\n",
      "73/73 [==============================] - 49s 669ms/step - loss: 0.6288 - accuracy: 0.8020 - val_loss: 0.5173 - val_accuracy: 0.8379\n",
      "Epoch 10/25\n",
      "73/73 [==============================] - 49s 668ms/step - loss: 0.5500 - accuracy: 0.8269 - val_loss: 0.6923 - val_accuracy: 0.7959\n",
      "Epoch 11/25\n",
      "73/73 [==============================] - 49s 669ms/step - loss: 0.6998 - accuracy: 0.7866 - val_loss: 0.4313 - val_accuracy: 0.8664\n",
      "Epoch 12/25\n",
      "73/73 [==============================] - 49s 668ms/step - loss: 0.4739 - accuracy: 0.8502 - val_loss: 0.3722 - val_accuracy: 0.8836\n",
      "Epoch 13/25\n",
      "73/73 [==============================] - 49s 676ms/step - loss: 0.4143 - accuracy: 0.8682 - val_loss: 0.3280 - val_accuracy: 0.9000\n",
      "Epoch 14/25\n",
      "73/73 [==============================] - 49s 665ms/step - loss: 0.3804 - accuracy: 0.8795 - val_loss: 0.2936 - val_accuracy: 0.9102\n",
      "Epoch 15/25\n",
      "73/73 [==============================] - 50s 682ms/step - loss: 0.3268 - accuracy: 0.8994 - val_loss: 0.2432 - val_accuracy: 0.9313\n",
      "Epoch 16/25\n",
      "73/73 [==============================] - 52s 709ms/step - loss: 0.2914 - accuracy: 0.9124 - val_loss: 0.2447 - val_accuracy: 0.9279\n",
      "Epoch 17/25\n",
      "73/73 [==============================] - 50s 684ms/step - loss: 0.2963 - accuracy: 0.9104 - val_loss: 0.2074 - val_accuracy: 0.9403\n",
      "Epoch 18/25\n",
      "73/73 [==============================] - 54s 735ms/step - loss: 0.2288 - accuracy: 0.9324 - val_loss: 0.1746 - val_accuracy: 0.9525\n",
      "Epoch 19/25\n",
      "73/73 [==============================] - 51s 695ms/step - loss: 0.2092 - accuracy: 0.9379 - val_loss: 0.1719 - val_accuracy: 0.9513\n",
      "Epoch 20/25\n",
      "73/73 [==============================] - 51s 694ms/step - loss: 0.1959 - accuracy: 0.9419 - val_loss: 0.1489 - val_accuracy: 0.9570\n",
      "Epoch 21/25\n",
      "73/73 [==============================] - 51s 698ms/step - loss: 0.1771 - accuracy: 0.9476 - val_loss: 0.1412 - val_accuracy: 0.9594\n",
      "Epoch 22/25\n",
      "73/73 [==============================] - 51s 696ms/step - loss: 0.1646 - accuracy: 0.9509 - val_loss: 0.1444 - val_accuracy: 0.9589\n",
      "Epoch 23/25\n",
      "73/73 [==============================] - 49s 675ms/step - loss: 0.1582 - accuracy: 0.9526 - val_loss: 0.1463 - val_accuracy: 0.9569\n",
      "Epoch 24/25\n",
      "73/73 [==============================] - 51s 701ms/step - loss: 0.1534 - accuracy: 0.9542 - val_loss: 0.1182 - val_accuracy: 0.9662\n",
      "Epoch 25/25\n",
      "73/73 [==============================] - 52s 716ms/step - loss: 0.1617 - accuracy: 0.9531 - val_loss: 0.3786 - val_accuracy: 0.8852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7192fc6090>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Train neural network using model_final\n",
    "model = model_final(preproc_english_sentences.shape,preproc_french_sentences.shape[1],len(english_tokenizer.word_index)+1,len(french_tokenizer.word_index)+1)\n",
    "model.summary()\n",
    "model.fit(preproc_english_sentences, preproc_french_sentences, batch_size=1024, epochs=25, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19864384",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85246/1276819928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98986802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 19:17:30.514934: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fe34cc59450> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fe34cc59210> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fe34d958610> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fe34d958ed0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e80a1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 19:30:40.048066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 19:30:40.048611: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-24 19:30:40.048695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-24 19:30:40.048772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-24 19:30:40.051153: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-24 19:30:40.051232: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-24 19:30:40.051300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-01-24 19:30:40.051315: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-24 19:30:40.051643: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07c66288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "elle conduit une une voiture voiture voiture <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Il a vu un vieux camion jaune\n",
      "Sample 2:\n",
      "new jersey est est en en et et il il il en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    \"\"\"\n",
    "    Gets predictions using the final model\n",
    "    :param x: Preprocessed English data\n",
    "    :param y: Preprocessed French data\n",
    "    :param x_tk: English tokenizer\n",
    "    :param y_tk: French tokenizer\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    ## DON'T EDIT ANYTHING BELOW THIS LINE\n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "\n",
    "    sentence = 'he saw a old yellow truck'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "\n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('Il a vu un vieux camion jaune')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))\n",
    "\n",
    "\n",
    "final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6a701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
